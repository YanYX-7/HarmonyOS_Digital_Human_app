import router from '@ohos.router'
import webSocket from '@ohos.net.webSocket'
import media from '@ohos.multimedia.media'
import audio from '@ohos.multimedia.audio'
import util from '@ohos.util'
import { BusinessError } from '@ohos.base'

// æ¶ˆæ¯ç±»å‹å®šä¹‰
interface ServerMessage {
  DataType: string
  Data: string
}

interface TTSData {
  Text: string
  AudioData: string
}

// èŠå¤©æ¶ˆæ¯å®šä¹‰
interface ChatMessage {
  type: 'user' | 'ai' | 'system'
  content: string
}

interface WebSocketConfig {
  systemMessage: string
  voiceType: string
}

interface SystemPromptData {
  Text: string
}

@Entry
@Component
struct ChatPage {
  @State showTextInput: boolean = false
  @State inputMessage: string = ''
  @State message3: string = 'æ™ºæ…§è¿ç»´æ•°å­—äºº\nå¾ˆé«˜å…´ä¸æ‚¨å¯¹è¯'
  @State chatMessages: ChatMessage[] = []
  @State isRecording: boolean = false
  @State isAISpeaking: boolean = false

  private videoController: VideoController = new VideoController()
  private socket: webSocket.WebSocket | null = null
  private audioPlayer: media.AVPlayer | null = null
  private audioCapturer: audio.AudioCapturer | null = null
  private audioQueue: ArrayBuffer[] = []
  private isPlaying: boolean = false
  private currentAIMessage: string = ''

  aboutToAppear() {
    this.connectWebSocket()
    this.initAudioPlayer()
  }

  aboutToDisappear() {
    this.disconnectWebSocket()
    this.releaseAudioResources()
  }

  // ==================== WebSocket è¿æ¥ç®¡ç† ====================

  connectWebSocket() {
    try {
      this.socket = webSocket.createWebSocket()
      this.socket.connect('ws://10.128.37.164:19465/recognition?isSendConfig=true')

      // è¿æ¥æˆåŠŸ
      this.socket.on('open', (err: BusinessError | undefined, value: Object | undefined): void => {
        if (!err) {
          console.log('WebSocketè¿æ¥æˆåŠŸ')
          this.message3 = 'æ™ºæ…§è¿ç»´æ•°å­—äºº\nè¿æ¥æˆåŠŸï¼Œå¯ä»¥å¼€å§‹å¯¹è¯'

          // å‘é€åˆå§‹é…ç½®
          const config: WebSocketConfig = {
            systemMessage: "æˆ‘æ˜¯å®å¤å¤§å­¦æ™ºèƒ½åŠ©æ‰‹å°é’",
            voiceType: "BV700_streaming"
          }
          this.socket?.send(JSON.stringify(config))

          // å¯åŠ¨è¯­éŸ³è¯†åˆ«
          this.startVoiceRecognition()
        } else {
          console.error('WebSocketè¿æ¥å¤±è´¥:', err)
          this.message3 = 'æ™ºæ…§è¿ç»´æ•°å­—äºº\nè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œ'
        }
      })

      // æ¥æ”¶æ¶ˆæ¯
      this.socket.on('message', (err: BusinessError | undefined, value: string |ArrayBuffer): void => {
        if (!err && typeof value === 'string') {
          this.handleServerMessage(value)
        }
      })

      // è¿æ¥å…³é—­
      this.socket.on('close', (err: BusinessError | undefined, value: webSocket.CloseResult | undefined) => {
        console.log('WebSocketè¿æ¥å·²å…³é—­')
        this.message3 = 'æ™ºæ…§è¿ç»´æ•°å­—äºº\nè¿æ¥å·²æ–­å¼€'
      })

      // é”™è¯¯å¤„ç†
      this.socket.on('error', (err: BusinessError): void => {
        console.error('WebSocketé”™è¯¯:', err)
      })

    } catch (error) {
      console.error('åˆ›å»ºWebSocketå¤±è´¥:', error)
    }
  }

  disconnectWebSocket() {
    if (this.socket) {
      this.socket.close()
      this.socket = null
    }
  }

  // ==================== æ¶ˆæ¯å¤„ç† ====================

  handleServerMessage(message: string) {
    try {
      const jsonData: ServerMessage = JSON.parse(message)

      switch (jsonData.DataType) {
        case 'TTS':
          // å¤„ç† TTS éŸ³é¢‘æ•°æ®
          this.handleTTSData(jsonData.Data)
          break

        case 'StartLLM':
          // LLM å¼€å§‹å¤„ç†
          this.handleStartLLM(jsonData.Data)
          break

        case 'SystemPrompt':
          // ç³»ç»Ÿæç¤º
          this.handleSystemPrompt(jsonData.Data)
          break
      }
    } catch (error) {
      console.error('è§£ææ¶ˆæ¯å¤±è´¥:', error)
    }
  }

  // å¤„ç† TTS æ•°æ®
  handleTTSData(data: string) {
    try {
      const ttsData: TTSData = JSON.parse(data)

      // æ·»åŠ æ–‡æœ¬åˆ°å½“å‰ AI æ¶ˆæ¯
      if (ttsData.Text && ttsData.Text.trim() !== '') {
        this.currentAIMessage += ttsData.Text

        // æ›´æ–°æœ€åä¸€æ¡ AI æ¶ˆæ¯
        if (this.chatMessages.length > 0 &&
          this.chatMessages[this.chatMessages.length - 1].type === 'ai') {
          this.chatMessages[this.chatMessages.length - 1].content = this.currentAIMessage
        }
      }

      // å¤„ç†éŸ³é¢‘æ•°æ®
      if (ttsData.AudioData && ttsData.AudioData.trim() !== '') {
        const audioBuffer = this.base64ToArrayBuffer(ttsData.AudioData)
        this.audioQueue.push(audioBuffer)
        this.playNextAudio()
      }

    } catch (error) {
      console.error('å¤„ç†TTSæ•°æ®å¤±è´¥:', error)
    }
  }

  // å¤„ç† LLM å¼€å§‹
  handleStartLLM(userInput: string) {
    // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    this.chatMessages.push({
      type: 'user',
      content: userInput
    })

    // åˆ›å»ºæ–°çš„ AI æ¶ˆæ¯å ä½
    this.currentAIMessage = ''
    this.chatMessages.push({
      type: 'ai',
      content: ''
    })

    // æ¸…ç©ºéŸ³é¢‘é˜Ÿåˆ—
    this.audioQueue = []
    this.isAISpeaking = true
    this.isRecording = false
  }

  // å¤„ç†ç³»ç»Ÿæç¤º
  handleSystemPrompt(data: string): void {
    try {
      const promptData: SystemPromptData = JSON.parse(data) as SystemPromptData
      const systemMessage: ChatMessage = {
        type: 'system',
        content: promptData.Text
      }
      this.chatMessages.push(systemMessage)

    } catch (error) {
      console.error('å¤„ç†ç³»ç»Ÿæç¤ºå¤±è´¥:', error)
    }
  }

  // ==================== éŸ³é¢‘æ’­æ”¾ ====================

  async initAudioPlayer(): Promise<void> {
    try {
      this.audioPlayer = await media.createAVPlayer()

      this.audioPlayer.on('stateChange', (state: media.AVPlayerState, reason: media.StateChangeReason): void => {
        console.log('æ’­æ”¾å™¨çŠ¶æ€:', state)

        if (state === 'completed') {
          this.onAudioPlayEnd()
        }
      })

    } catch (error) {
      console.error('åˆå§‹åŒ–éŸ³é¢‘æ’­æ”¾å™¨å¤±è´¥:', error)
    }
  }

  async playNextAudio() {
    if (this.isPlaying || this.audioQueue.length === 0) {
      return
    }

    this.isPlaying = true
    const audioData = this.audioQueue.shift()

    if (audioData && this.audioPlayer) {
      try {
        // å°† ArrayBuffer è½¬æ¢ä¸ºå¯æ’­æ”¾çš„æ ¼å¼
        // æ³¨æ„ï¼šè¿™é‡Œéœ€è¦æ ¹æ®å®é™…éŸ³é¢‘æ ¼å¼è¿›è¡Œè°ƒæ•´
        // å¯èƒ½éœ€è¦å†™å…¥ä¸´æ—¶æ–‡ä»¶æˆ–ä½¿ç”¨å…¶ä»–æ–¹å¼
        await this.playAudioBuffer(audioData)

      } catch (error) {
        console.error('æ’­æ”¾éŸ³é¢‘å¤±è´¥:', error)
        this.isPlaying = false
        this.playNextAudio()
      }
    }
  }

  async playAudioBuffer(buffer: ArrayBuffer): Promise<void> {
    // TODO: å®ç°éŸ³é¢‘æ’­æ”¾é€»è¾‘
    // HarmonyOS çš„éŸ³é¢‘æ’­æ”¾éœ€è¦æ–‡ä»¶è·¯å¾„æˆ– FD
    // å¯èƒ½éœ€è¦å…ˆå°† buffer å†™å…¥ä¸´æ—¶æ–‡ä»¶

    // ä¸´æ—¶æ¨¡æ‹Ÿæ’­æ”¾å®Œæˆ
    setTimeout((): void => {
      this.onAudioPlayEnd()
    }, 1000)
  }

  onAudioPlayEnd() {
    this.isPlaying = false

    if (this.audioQueue.length > 0) {
      this.playNextAudio()
    } else {
      this.isAISpeaking = false
      if (!this.showTextInput) {
        this.isRecording = true
      }
    }
  }

  // ==================== è¯­éŸ³è¯†åˆ« ====================

  async startVoiceRecognition() {
    if (this.showTextInput || this.isRecording) {
      return
    }

    try {
      // åˆ›å»ºéŸ³é¢‘é‡‡é›†å™¨
      const audioStreamInfo: audio.AudioStreamInfo = {
        samplingRate: audio.AudioSamplingRate.SAMPLE_RATE_16000,
        channels: audio.AudioChannel.CHANNEL_1,
        sampleFormat: audio.AudioSampleFormat.SAMPLE_FORMAT_S16LE,
        encodingType: audio.AudioEncodingType.ENCODING_TYPE_RAW
      }

      const audioCapturerInfo: audio.AudioCapturerInfo = {
        source: audio.SourceType.SOURCE_TYPE_MIC,
        capturerFlags: 0
      }

      const audioCapturerOptions: audio.AudioCapturerOptions = {
        streamInfo: audioStreamInfo,
        capturerInfo: audioCapturerInfo
      }

      this.audioCapturer = await audio.createAudioCapturer(audioCapturerOptions)

      // ç›‘å¬éŸ³é¢‘æ•°æ®
      this.audioCapturer.on('readData', (buffer: ArrayBuffer): void => {
        if (this.isRecording && this.socket) {
          // å‘é€éŸ³é¢‘æ•°æ®åˆ°æœåŠ¡å™¨
          this.socket.send(buffer, (err: BusinessError | undefined): void => {
            if (err) {
              console.error('å‘é€éŸ³é¢‘æ•°æ®å¤±è´¥:', err)
            }
          })
        }
      })

      // å¼€å§‹å½•éŸ³
      await this.audioCapturer.start()
      this.isRecording = true

    } catch (error) {
      console.error('å¯åŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥:', error)
    }
  }

  async stopVoiceRecognition() {
    if (this.audioCapturer) {
      try {
        await this.audioCapturer.stop()
        this.isRecording = false
      } catch (error) {
        console.error('åœæ­¢è¯­éŸ³è¯†åˆ«å¤±è´¥:', error)
      }
    }
  }

  // ==================== å·¥å…·å‡½æ•° ====================

  base64ToArrayBuffer(base64: string): ArrayBuffer {
    try {
      // ä½¿ç”¨ HarmonyOS çš„ Base64 è§£ç 
      const helper = new util.Base64Helper()
      const uint8Array: Uint8Array = helper.decodeSync(base64)
      return uint8Array.buffer
    } catch (error) {
      console.error('Base64è§£ç å¤±è´¥:', error)
      // è¿”å›ç©ºçš„ ArrayBuffer
      return new ArrayBuffer(0)
    }
  }

  releaseAudioResources() {
    if (this.audioPlayer) {
      this.audioPlayer.release()
      this.audioPlayer = null
    }

    if (this.audioCapturer) {
      this.audioCapturer.release()
      this.audioCapturer = null
    }
  }

  // ==================== æ–‡æœ¬æ¶ˆæ¯å‘é€ ====================

  sendMessage(): void {
    if (this.inputMessage.trim() === '') return

    // åœæ­¢è¯­éŸ³è¯†åˆ«
    this.stopVoiceRecognition()

    const userMessage: ChatMessage = {
      type: 'user',
      content: this.inputMessage
    }
    this.chatMessages.push(userMessage)

    // å‘é€æ–‡æœ¬åˆ°æœåŠ¡å™¨
    if (this.socket) {
      this.socket.send(this.inputMessage, (err: BusinessError | undefined): void => {
        if (err) {
          console.error('å‘é€æ¶ˆæ¯å¤±è´¥:', err)
        } else {
          console.log('æ¶ˆæ¯å‘é€æˆåŠŸ:', this.inputMessage)
        }
      })
    }

    this.inputMessage = ''
  }

  // ==================== UI æ„å»º ====================

  build() {
    Stack({ alignContent: Alignment.BottomEnd }) {
      // å…¨å±æ•°å­—äººè§†é¢‘
      Video({
        src: $rawfile('digital_human.mp4'),
        controller: this.videoController
      })
        .width('100%')
        .height('100%')
        .objectFit(ImageFit.Cover)
        .autoPlay(true)
        .loop(true)
        .controls(false)
        .backgroundColor(Color.Black)

      // é¡¶éƒ¨æ ‡é¢˜
      Column() {
        Text(this.message3)
          .fontSize(24)
          .fontWeight(FontWeight.Bold)
          .fontColor(Color.White)
          .textAlign(TextAlign.Center)
          .textShadow({
            radius: 2,
            color: Color.Black,
            offsetX: 1,
            offsetY: 1
          })
      }
      .position({ x: 0, y: 90 })
      .width('100%')
      .justifyContent(FlexAlign.Center)

      // èŠå¤©æ¶ˆæ¯åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
      if (this.chatMessages.length > 0) {
        List({ space: 10 }) {
          ForEach(this.chatMessages, (msg: ChatMessage, index: number) => {
            ListItem() {
              this.MessageBubble(msg)
            }
          })
        }
        .width('90%')
        .height('20%')
        .position({ x: '5%', y: '70%' })
        .backgroundColor('rgba(0, 0, 0, 0.3)')
        .borderRadius(12)
        .padding(10)
      }

      // å³ä¸‹è§’æŒ‰é’®
      if (!this.showTextInput) {
        Column() {
          // å½•éŸ³çŠ¶æ€æŒ‡ç¤º
          if (this.isRecording) {
            Row() {
              Text('ğŸ¤')
                .fontSize(20)
                .margin({ right: 8 })
              Text('æ­£åœ¨è†å¬...')
                .fontSize(14)
                .fontColor(Color.White)
            }
            .padding(10)
            .backgroundColor('rgba(255, 0, 0, 0.6)')
            .borderRadius(20)
            .margin({ bottom: 10 })
          }

          Button('æ–‡æœ¬è¾“å…¥')
            .width(100)
            .height(40)
            .fontSize(15)
            .fontWeight(FontWeight.Medium)
            .fontColor(Color.White)
            .borderRadius(20)
            .backgroundColor('#4A4A4A')
            .margin({ bottom: 10 })
            .onClick((): void => {
              this.showTextInput = true
              this.stopVoiceRecognition()
            })

          Button('è¿”  å›')
            .width(100)
            .height(40)
            .fontSize(15)
            .fontWeight(FontWeight.Medium)
            .fontColor(Color.White)
            .borderRadius(20)
            .backgroundColor('#4A4A4A')
            .onClick((): void => {
              router.back()
            })
        }
        .position({ x: '75%', y: '80%' })
      }

      // åº•éƒ¨æ–‡å­—è¾“å…¥åŒºåŸŸ
      if (this.showTextInput) {
        Column() {
          Row() {
            TextInput({
              placeholder: 'è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...',
              text: this.inputMessage
            })
              .layoutWeight(1)
              .height(45)
              .borderRadius(22.5)
              .padding({ left: 15, right: 15 })
              .backgroundColor('rgba(255, 255, 255, 0.9)')
              .onChange((value: string): void => {
                this.inputMessage = value
              })

            Button('å‘é€')
              .width(80)
              .height(45)
              .fontSize(16)
              .fontWeight(FontWeight.Medium)
              .fontColor(Color.White)
              .borderRadius(22.5)
              .backgroundColor('#4A4A4A')
              .margin({ left: 10 })
              .enabled(this.inputMessage.trim() !== '')
              .onClick((): void => {
                this.sendMessage()
              })
          }
          .width('100%')
          .padding({ left: 20, right: 20 })
        }
        .width('100%')
        .backgroundColor('rgba(0, 0, 0, 0.8)')
        .padding({ top: 15, bottom: 30 })
        .position({ x: 0, y: '100%' })
        .translate({ x: 0, y: -60 })
      }

      // æ–‡æœ¬è¾“å…¥æ¨¡å¼ä¸‹çš„å³ä¾§æŒ‰é’®
      if (this.showTextInput) {
        Column() {
          Button('è¯­éŸ³äº¤æµ')
            .width(100)
            .height(40)
            .fontSize(15)
            .fontWeight(FontWeight.Medium)
            .fontColor(Color.White)
            .borderRadius(20)
            .backgroundColor('#6c757d')
            .margin({ bottom: 10 })
            .onClick(() => {
              this.showTextInput = false
              this.startVoiceRecognition()
            })

          Button('è¿”  å›')
            .width(100)
            .height(40)
            .fontSize(15)
            .fontWeight(FontWeight.Medium)
            .fontColor(Color.White)
            .borderRadius(20)
            .backgroundColor('#6c757d')
            .onClick(() => {
              router.back()
            })
        }
        .position({ x: '75%', y: '65%' })
      }
    }
    .width('100%')
    .height('100%')
  }

  // æ¶ˆæ¯æ°”æ³¡ç»„ä»¶
  @Builder MessageBubble(msg: ChatMessage) {
    Row() {
      if (msg.type === 'user') {
        Blank()
      }

      Text(msg.content)
        .fontSize(14)
        .fontColor(Color.White)
        .padding(10)
        .borderRadius(8)
        .backgroundColor(
          msg.type === 'user' ? '#007AFF' :
            msg.type === 'ai' ? '#34C759' :
              '#FF9500'
        )
        .maxLines(10)
        .textOverflow({ overflow: TextOverflow.Ellipsis })

      if (msg.type === 'ai' || msg.type === 'system') {
        Blank()
      }
    }
    .width('100%')
  }
}
